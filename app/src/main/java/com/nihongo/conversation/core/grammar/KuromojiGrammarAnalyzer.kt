package com.nihongo.conversation.core.grammar

import com.atilika.kuromoji.ipadic.Token
import com.atilika.kuromoji.ipadic.Tokenizer
import com.nihongo.conversation.domain.model.GrammarComponent
import com.nihongo.conversation.domain.model.GrammarExplanation
import com.nihongo.conversation.domain.model.GrammarType
import com.nihongo.conversation.domain.model.FuriganaType

/**
 * Kuromoji-based Grammar Analyzer
 *
 * Uses Kuromoji (Japanese morphological analyzer) for accurate, fast, offline grammar analysis.
 * Replaces Gemini API calls for grammar analysis to improve speed and save API quota.
 *
 * Features:
 * - 100% offline (no API calls)
 * - Fast analysis (< 100ms per sentence)
 * - Accurate part-of-speech tagging (MeCab IPADIC dictionary)
 * - Thread-safe singleton with lazy initialization
 *
 * @see com.atilika.kuromoji.ipadic.Tokenizer
 */
object KuromojiGrammarAnalyzer {

    private const val TAG = "KuromojiGrammar"

    // Lazy initialization to avoid loading dictionary on app startup
    private val tokenizer: Tokenizer by lazy {
        android.util.Log.d(TAG, "Initializing Kuromoji tokenizer (first use only)...")
        val start = System.currentTimeMillis()
        val t = Tokenizer()
        val elapsed = System.currentTimeMillis() - start
        android.util.Log.d(TAG, "Tokenizer initialized in ${elapsed}ms")
        t
    }

    /**
     * Analyze Japanese sentence using Kuromoji morphological analyzer
     *
     * @param sentence Japanese text to analyze
     * @param userLevel User JLPT level (1=N5/N4, 2=N3/N2, 3=N1) - affects explanation detail
     * @return GrammarExplanation with components, examples, and patterns
     */
    fun analyzeSentence(sentence: String, userLevel: Int = 1): GrammarExplanation {
        val startTime = System.currentTimeMillis()
        android.util.Log.d(TAG, "Analyzing: '$sentence' (level=$userLevel)")

        try {
            // Tokenize with Kuromoji
            val tokens = tokenizer.tokenize(sentence)
            android.util.Log.d(TAG, "Tokenized into ${tokens.size} tokens")

            // Track position manually since Kuromoji doesn't provide character positions
            var currentPosition = 0

            // Convert tokens to grammar components
            val components = tokens.mapIndexed { index, token ->
                val pos = token.partOfSpeechLevel1  // Main POS (å‹•è©, åŠ©è©, etc.)
                val grammarType = mapPosToGrammarType(token)
                val explanation = generateExplanation(token, userLevel)

                android.util.Log.v(TAG, "  [$index] ${token.surface} â†’ $pos â†’ $grammarType")

                val startIndex = currentPosition
                val endIndex = currentPosition + token.surface.length
                currentPosition = endIndex

                GrammarComponent(
                    text = token.surface,
                    type = grammarType,
                    explanation = explanation,
                    startIndex = startIndex,
                    endIndex = endIndex
                )
            }.filter { component ->
                // Filter out punctuation symbols, keep only meaningful symbols
                if (component.type == GrammarType.SYMBOL) {
                    // Keep meaningful symbols (ï¼Ÿï¼ã€œãƒ»), filter out punctuation (ã€‚ã€ï¼ˆï¼‰ã€Œã€ç­‰)
                    component.text in listOf("ï¼Ÿ", "ï¼", "ã€œ", "ãƒ»", "?", "!")
                } else {
                    true  // Keep all non-symbol components
                }
            }

            // Generate overall and detailed explanations
            val overallExplanation = generateOverallExplanation(sentence, components, userLevel)
            val detailedExplanation = generateDetailedExplanation(components, userLevel)
            val examples = generateExamples(components)
            val relatedPatterns = getRelatedPatterns(components)

            val elapsed = System.currentTimeMillis() - startTime
            android.util.Log.d(TAG, "âœ… Analysis completed in ${elapsed}ms")

            return GrammarExplanation(
                originalText = sentence,
                components = components,
                overallExplanation = overallExplanation,
                detailedExplanation = detailedExplanation,
                examples = examples,
                relatedPatterns = relatedPatterns
            )
        } catch (e: Exception) {
            android.util.Log.e(TAG, "âŒ Analysis failed: ${e.message}", e)

            // Fallback to LocalGrammarAnalyzer on error
            return LocalGrammarAnalyzer.analyzeSentence(sentence, userLevel)
        }
    }

    /**
     * Map Kuromoji POS tags to GrammarType
     *
     * Kuromoji provides detailed POS information:
     * - partOfSpeechLevel1: Main category (å‹•è©, åŠ©è©, etc.)
     * - partOfSpeechLevel2: Sub-category
     * - partOfSpeechLevel3: Detailed classification
     * - conjugationForm: æ´»ç”¨å½¢ (é€£ç”¨å½¢, çµ‚æ­¢å½¢, etc.)
     *
     * Updated 2025-11-02: Accurate mapping to 12 GrammarTypes
     */
    private fun mapPosToGrammarType(token: Token): GrammarType {
        return when (token.partOfSpeechLevel1) {
            "å‹•è©" -> GrammarType.VERB
            "åŠ©è©" -> GrammarType.PARTICLE
            "åŠ©å‹•è©" -> GrammarType.AUXILIARY
            "åè©" -> GrammarType.NOUN
            "å½¢å®¹è©" -> GrammarType.ADJECTIVE
            "å‰¯è©" -> GrammarType.ADVERB
            "é€£ä½“è©" -> GrammarType.RENTAISHI         // â† Fixed: was ADJECTIVE
            "æ¥ç¶šè©" -> GrammarType.CONJUNCTION       // â† Fixed: was EXPRESSION
            "æ„Ÿå‹•è©" -> GrammarType.INTERJECTION      // â† Fixed: was EXPRESSION
            "æ¥é ­è©" -> GrammarType.PREFIX            // â† Fixed: was EXPRESSION
            "è¨˜å·" -> GrammarType.SYMBOL              // â† Fixed: was EXPRESSION
            else -> GrammarType.EXPRESSION
        }
    }

    /**
     * Generate Korean explanation for a token based on POS
     */
    private fun generateExplanation(token: Token, userLevel: Int): String {
        val mainPos = token.partOfSpeechLevel1
        val subPos = token.partOfSpeechLevel2 ?: "*"
        val conjugation = token.conjugationForm ?: "*"

        return when (mainPos) {
            "å‹•è©" -> {
                val baseForm = token.baseForm
                val meaning = JMdictHelper.lookup(baseForm)

                val detail = when (conjugation) {
                    "é€£ç”¨å½¢" -> "ì—°ìš©í˜• (ã¦í˜•, ãŸí˜• ì•)"
                    "çµ‚æ­¢å½¢" -> "ì¢…ì§€í˜• (ë¬¸ì¥ ë)"
                    "æœªç„¶å½¢" -> "ë¯¸ì—°í˜• (ãªã„, ã† ì•)"
                    "ä»®å®šå½¢" -> "ê°€ì •í˜• (ã° ì•)"
                    "å‘½ä»¤å½¢" -> "ëª…ë ¹í˜•"
                    "åŸºæœ¬å½¢" -> "ê¸°ë³¸í˜•"
                    else -> "ë™ì‚¬"
                }

                if (meaning != null) {
                    if (userLevel == 1) "ë™ì‚¬: $meaning ($detail)" else "$meaning ($detail)"
                } else {
                    if (userLevel == 1) "ë™ì‚¬: $detail" else detail
                }
            }
            "åŠ©è©" -> {
                val particleType = when (subPos) {
                    "æ ¼åŠ©è©" -> "ê²©ì¡°ì‚¬"
                    "æ¥ç¶šåŠ©è©" -> "ì ‘ì†ì¡°ì‚¬"
                    "å‰¯åŠ©è©" -> "ë¶€ì¡°ì‚¬"
                    "çµ‚åŠ©è©" -> "ì¢…ì¡°ì‚¬"
                    else -> "ì¡°ì‚¬"
                }
                getParticleExplanation(token.surface, particleType, userLevel)
            }
            "åŠ©å‹•è©" -> {
                when (token.surface) {
                    "ã§ã™" -> "ì •ì¤‘ì²´/ë‹¨ì •"
                    "ã " -> "ë‹¨ì •/í‰ì„œ"
                    "ã¾ã™" -> "ì •ì¤‘ì²´ ë™ì‚¬"
                    "ãŸ" -> "ê³¼ê±°/ì™„ë£Œ"
                    "ãªã„" -> "ë¶€ì •"
                    "ã‚ˆã†ã ", "ãã†ã " -> "ì¶”ì¸¡/ì–‘íƒœ"
                    "ãŸã„" -> "í¬ë§"
                    "ã‚Œã‚‹", "ã‚‰ã‚Œã‚‹" -> "ìˆ˜ë™/ê°€ëŠ¥/ì¡´ê²½"
                    "ã›ã‚‹", "ã•ã›ã‚‹" -> "ì‚¬ì—­"
                    else -> "ì¡°ë™ì‚¬"
                }
            }
            "åè©" -> {
                // Try to lookup meaning in dictionary
                val baseForm = token.baseForm  // Get dictionary form
                val meaning = JMdictHelper.lookup(baseForm)
                    ?: JMdictHelper.lookup(token.surface)  // Fallback to surface form

                if (meaning != null) {
                    when (subPos) {
                        "ä»£åè©" -> "ëŒ€ëª…ì‚¬: $meaning"
                        "æ•°" -> "ìˆ«ì: $meaning"
                        "éè‡ªç«‹" -> "ì˜ì¡´ëª…ì‚¬: $meaning"
                        else -> "ëª…ì‚¬: $meaning"
                    }
                } else {
                    // No dictionary entry found, show base form
                    val info = if (baseForm != token.surface) {
                        " (${baseForm})"
                    } else {
                        ""
                    }
                    when (subPos) {
                        "ä»£åè©" -> "ëŒ€ëª…ì‚¬$info"
                        "æ•°" -> "ìˆ«ì$info"
                        "éè‡ªç«‹" -> "ì˜ì¡´ëª…ì‚¬$info"
                        else -> "ëª…ì‚¬$info"
                    }
                }
            }
            "å½¢å®¹è©" -> {
                val baseForm = token.baseForm
                val meaning = JMdictHelper.lookup(baseForm)
                    ?: JMdictHelper.lookup(token.surface)

                if (meaning != null) {
                    if (conjugation != "*") "í˜•ìš©ì‚¬: $meaning ($conjugation)"
                    else "í˜•ìš©ì‚¬: $meaning"
                } else {
                    if (conjugation != "*") "í˜•ìš©ì‚¬ ($conjugation)"
                    else "í˜•ìš©ì‚¬"
                }
            }
            "å‰¯è©" -> {
                val meaning = JMdictHelper.lookup(token.surface)
                    ?: JMdictHelper.lookup(token.baseForm)

                if (meaning != null) "ë¶€ì‚¬: $meaning"
                else "ë¶€ì‚¬"
            }
            "é€£ä½“è©" -> "ì—°ì²´ì‚¬"
            "æ¥ç¶šè©" -> "ì ‘ì†ì‚¬"
            "æ„Ÿå‹•è©" -> {
                val meaning = JMdictHelper.lookup(token.surface)
                if (meaning != null) "ê°íƒ„ì‚¬: $meaning"
                else "ê°íƒ„ì‚¬"
            }
            "æ¥é ­è©" -> "ì ‘ë‘ì‚¬"
            "è¨˜å·" -> when (subPos) {
                "å¥ç‚¹" -> "ë§ˆì¹¨í‘œ"
                "èª­ç‚¹" -> "ì‰¼í‘œ"
                else -> "ê¸°í˜¸"
            }
            else -> "ê¸°íƒ€"
        }
    }

    /**
     * Get particle-specific explanation (similar to LocalGrammarAnalyzer)
     */
    private fun getParticleExplanation(particle: String, type: String, userLevel: Int): String {
        val info = when (particle) {
            "ã¯" -> "ì£¼ì œ í‘œì‹œ (ì€/ëŠ”)"
            "ãŒ" -> "ì£¼ì–´ í‘œì‹œ (ì´/ê°€)"
            "ã‚’" -> "ëª©ì ì–´ í‘œì‹œ (ì„/ë¥¼)"
            "ã«" -> "ë°©í–¥/ì‹œê°„/ëŒ€ìƒ (ì—/ì—ê²Œ)"
            "ã¸" -> "ë°©í–¥ (ìœ¼ë¡œ)"
            "ã¨" -> "í•¨ê»˜/ì¸ìš© (ì™€/ê³¼)"
            "ã§" -> "ìˆ˜ë‹¨/ì¥ì†Œ (ì—ì„œ/ë¡œ)"
            "ã‹ã‚‰" -> "ì‹œì‘ì  (ë¶€í„°/ì—ì„œ)"
            "ã¾ã§" -> "ì¢…ì  (ê¹Œì§€)"
            "ã®" -> "ì†Œìœ /ê´€ê³„ (~ì˜)"
            "ã‚‚" -> "ì¶”ê°€ (ë„/ì—­ì‹œ)"
            "ã‚„" -> "ì˜ˆì‹œ ë‚˜ì—´ (ì´ë‚˜/ì™€)"
            "ã‹" -> "ì˜ë¬¸ (~ì¸ê°€)"
            "ã­" -> "í™•ì¸ (~ë„¤ìš”)"
            "ã‚ˆ" -> "ê°•ì¡° (~ìš”)"
            else -> type
        }

        return if (userLevel == 1) "$type: $info" else info
    }

    /**
     * Generate overall explanation based on sentence structure
     */
    private fun generateOverallExplanation(
        sentence: String,
        components: List<GrammarComponent>,
        userLevel: Int
    ): String {
        val hasVerb = components.any { it.type == GrammarType.VERB }
        val hasAuxiliary = components.any { it.type == GrammarType.AUXILIARY }
        val particles = components.filter { it.type == GrammarType.PARTICLE }

        return when {
            sentence.endsWith("ã§ã™ã‹") || sentence.endsWith("ã¾ã™ã‹") ->
                "ì •ì¤‘í•œ ì˜ë¬¸ë¬¸ì…ë‹ˆë‹¤. ìƒëŒ€ë°©ì—ê²Œ ì˜ˆì˜ ë°”ë¥´ê²Œ ì§ˆë¬¸í•˜ëŠ” í‘œí˜„ì´ì—ìš”."

            sentence.endsWith("ã‹") ->
                "ì˜ë¬¸ë¬¸ì…ë‹ˆë‹¤. ë¬´ì–¸ê°€ë¥¼ ë¬»ëŠ” ë¬¸ì¥ì´ì—ìš”."

            sentence.contains("ãã ã•ã„") ->
                "ìš”ì²­ì´ë‚˜ ë¶€íƒì„ ë‚˜íƒ€ë‚´ëŠ” ë¬¸ì¥ì…ë‹ˆë‹¤. ê³µì†í•˜ê²Œ ë¶€íƒí•˜ëŠ” í‘œí˜„ì´ì—ìš”."

            sentence.endsWith("ã¾ã—ãŸ") || sentence.endsWith("ã§ã—ãŸ") ->
                "ê³¼ê±°í˜• ì •ì¤‘ì²´ ë¬¸ì¥ì…ë‹ˆë‹¤. ì´ë¯¸ ì¼ì–´ë‚œ ì¼ì„ ì •ì¤‘í•˜ê²Œ í‘œí˜„í•´ìš”."

            sentence.endsWith("ã¾ã™") || sentence.endsWith("ã§ã™") ->
                "í˜„ì¬ ë˜ëŠ” ë¯¸ë˜í˜• ì •ì¤‘ì²´ ë¬¸ì¥ì…ë‹ˆë‹¤. ì˜ˆì˜ ë°”ë¥¸ í‘œí˜„ì´ì—ìš”."

            sentence.contains("ã¾ã›ã‚“") || components.any { it.text == "ãªã„" } ->
                "ë¶€ì •ë¬¸ì…ë‹ˆë‹¤. ì–´ë–¤ ë™ì‘ì„ í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ì˜ë¯¸ì˜ˆìš”."

            components.any { it.text == "ãŸã„" } ->
                "í¬ë§ì´ë‚˜ ìš•êµ¬ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë¬¸ì¥ì…ë‹ˆë‹¤. ~í•˜ê³  ì‹¶ë‹¤ëŠ” í‘œí˜„ì´ì—ìš”."

            hasVerb && hasAuxiliary && particles.isNotEmpty() ->
                "ê¸°ë³¸ì ì¸ ì¼ë³¸ì–´ ë¬¸ì¥ êµ¬ì¡°ë¥¼ ê°–ì¶˜ ë¬¸ì¥ì…ë‹ˆë‹¤. ë™ì‚¬, ì¡°ì‚¬, ì¡°ë™ì‚¬ê°€ ì‚¬ìš©ë˜ì—ˆì–´ìš”."

            else ->
                "ì¼ë³¸ì–´ ë¬¸ì¥ì…ë‹ˆë‹¤. ${components.size}ê°œì˜ í˜•íƒœì†Œë¡œ êµ¬ì„±ë˜ì–´ ìˆì–´ìš”."
        }
    }

    /**
     * Generate detailed explanation with component breakdown
     */
    private fun generateDetailedExplanation(
        components: List<GrammarComponent>,
        userLevel: Int
    ): String {
        val particles = components.filter { it.type == GrammarType.PARTICLE }
        val verbs = components.filter { it.type == GrammarType.VERB }
        val auxiliaries = components.filter { it.type == GrammarType.AUXILIARY }
        val nouns = components.filter { it.type == GrammarType.NOUN }

        val parts = mutableListOf<String>()

        if (nouns.isNotEmpty()) {
            val nounList = nouns.take(3).joinToString(", ") { "'${it.text}'" }
            parts.add("ëª…ì‚¬ [$nounList] ë“±ì´ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
        }

        if (particles.isNotEmpty()) {
            val particleList = particles.map { it.text }.distinct().joinToString(", ")
            parts.add("ì¡°ì‚¬ [${particleList}]ê°€ ë¬¸ì¥ êµ¬ì¡°ë¥¼ ë§Œë“¤ê³  ìˆìŠµë‹ˆë‹¤.")
        }

        if (verbs.isNotEmpty()) {
            parts.add("${verbs.size}ê°œì˜ ë™ì‚¬ê°€ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
        }

        if (auxiliaries.isNotEmpty()) {
            val auxList = auxiliaries.map { it.text }.distinct().joinToString(", ")
            parts.add("ì¡°ë™ì‚¬ [${auxList}]ë¡œ ì •ì¤‘ë„ë‚˜ ì‹œì œë¥¼ í‘œí˜„í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
        }

        when (userLevel) {
            1 -> parts.add("ğŸ’¡ ì´ˆê¸‰ íŒ: ì¡°ì‚¬ì™€ ë™ì‚¬ í™œìš©ì— ì£¼ëª©í•˜ì„¸ìš”.")
            2 -> parts.add("ğŸ’¡ ì¤‘ê¸‰ íŒ: ë¬¸ì¥ì˜ ë‰˜ì•™ìŠ¤ì™€ ì •ì¤‘ë„ë¥¼ íŒŒì•…í•´ë³´ì„¸ìš”.")
            3 -> parts.add("ğŸ’¡ ê³ ê¸‰ íŒ: ë” ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ìœ¼ë¡œ ë°”ê¿”ë³´ëŠ” ì—°ìŠµì„ í•´ë³´ì„¸ìš”.")
        }

        if (parts.isEmpty()) {
            parts.add("í˜•íƒœì†Œ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        }

        return parts.joinToString(" ")
    }

    /**
     * Generate example sentences based on detected patterns
     */
    private fun generateExamples(components: List<GrammarComponent>): List<String> {
        val examples = mutableListOf<String>()

        if (components.any { it.text == "ã¯" }) {
            examples.add("ç§ã¯å­¦ç”Ÿã§ã™ã€‚(ì €ëŠ” í•™ìƒì…ë‹ˆë‹¤)")
        }

        if (components.any { it.text == "ã‚’" }) {
            examples.add("æœ¬ã‚’èª­ã¿ã¾ã™ã€‚(ì±…ì„ ì½ìŠµë‹ˆë‹¤)")
        }

        if (components.any { it.text == "ã¾ã™" }) {
            examples.add("æ¯æ—¥å‹‰å¼·ã—ã¾ã™ã€‚(ë§¤ì¼ ê³µë¶€í•©ë‹ˆë‹¤)")
        }

        if (components.any { it.text == "ãŸã„" }) {
            examples.add("æ—¥æœ¬ã¸è¡ŒããŸã„ã§ã™ã€‚(ì¼ë³¸ì— ê°€ê³  ì‹¶ìŠµë‹ˆë‹¤)")
        }

        if (components.any { it.text == "ãã ã•ã„" }) {
            examples.add("æ•™ãˆã¦ãã ã•ã„ã€‚(ê°€ë¥´ì³ ì£¼ì„¸ìš”)")
        }

        return examples.take(3) // Limit to 3 examples
    }

    /**
     * Get related grammar patterns
     */
    private fun getRelatedPatterns(components: List<GrammarComponent>): List<String> {
        val patterns = mutableSetOf<String>()

        if (components.any { it.text == "ã¯" }) {
            patterns.add("ã€œã¯ã€œã§ã™ (ì£¼ì œ ì œì‹œ)")
        }

        if (components.any { it.text == "ã‚’" }) {
            patterns.add("ã€œã‚’ã€œã™ã‚‹ (íƒ€ë™ì‚¬ ë¬¸í˜•)")
        }

        if (components.any { it.text == "ã¾ã™" }) {
            patterns.add("ã¾ã™í˜• (ì •ì¤‘ì²´)")
        }

        if (components.any { it.type == GrammarType.VERB && it.explanation.contains("é€£ç”¨å½¢") }) {
            patterns.add("ã€œã¦í˜• (ì—°ìš©í˜• í™œìš©)")
        }

        if (components.any { it.text == "ãŸã„" }) {
            patterns.add("ã€œãŸã„ (í¬ë§ í‘œí˜„)")
        }

        if (components.any { it.text == "ãªã„" }) {
            patterns.add("ã€œãªã„ (ë¶€ì •í˜•)")
        }

        return patterns.take(4).toList()
    }

    /**
     * Pre-load tokenizer (optional, call on app startup for faster first analysis)
     */
    fun preload() {
        android.util.Log.d(TAG, "Preloading Kuromoji tokenizer...")
        tokenizer // Access to trigger lazy initialization
    }

    /**
     * Convert Japanese text (including kanji) to hiragana readings
     *
     * Uses Kuromoji's reading information to convert kanji to hiragana.
     * This is useful for pronunciation guides.
     *
     * @param japanese Japanese text (may contain kanji, hiragana, katakana)
     * @return List of reading strings for each token
     *
     * Example:
     * - Input: "æ³¨æ–‡ã—ã¦ãã ã•ã„"
     * - Output: ["ã¡ã‚…ã†ã‚‚ã‚“", "ã—ã¦", "ãã ã•ã„"]
     */
    fun getReadings(japanese: String): List<String> {
        return try {
            tokenizer.tokenize(japanese).map { token ->
                // Use reading if available (converts kanji to hiragana)
                // Otherwise use surface form (already hiragana/katakana)
                token.reading ?: token.surface
            }
        } catch (e: Exception) {
            android.util.Log.e(TAG, "Failed to get readings", e)
            // Fallback: return original text as single token
            listOf(japanese)
        }
    }

    /**
     * Adds furigana (reading guide) to kanji characters in Japanese text
     *
     * Examples:
     * - Input: "æ³¨æ–‡ã—ã¦ãã ã•ã„", type: HIRAGANA
     *   Output: "æ³¨æ–‡(ã¡ã‚…ã†ã‚‚ã‚“)ã—ã¦ãã ã•ã„"
     *
     * - Input: "æ³¨æ–‡ã—ã¦ãã ã•ã„", type: KATAKANA
     *   Output: "æ³¨æ–‡(ãƒãƒ¥ã‚¦ãƒ¢ãƒ³)ã—ã¦ãã ã•ã„"
     *
     * @param text Japanese text that may contain kanji
     * @param type Furigana display type (HIRAGANA or KATAKANA)
     * @return Text with furigana in parentheses after kanji words
     */
    fun addFuriganaToKanji(text: String, type: FuriganaType = FuriganaType.HIRAGANA): String {
        return try {
            val tokens = tokenizer.tokenize(text)
            val result = StringBuilder()

            tokens.forEach { token ->
                val surface = token.surface
                val reading = token.reading

                // Check if this token contains kanji
                val hasKanji = surface.any { char ->
                    char in '\u4E00'..'\u9FFF' // CJK Unified Ideographs range
                }

                if (hasKanji && reading != null && reading != surface) {
                    // Convert reading to desired type
                    val displayReading = when (type) {
                        FuriganaType.HIRAGANA -> reading  // Kuromoji provides hiragana by default
                        FuriganaType.KATAKANA -> hiraganaToKatakana(reading)
                    }
                    // Add furigana: "æ³¨æ–‡(ã¡ã‚…ã†ã‚‚ã‚“)" or "æ³¨æ–‡(ãƒãƒ¥ã‚¦ãƒ¢ãƒ³)"
                    result.append(surface).append("(").append(displayReading).append(")")
                } else {
                    // No kanji or no reading available, use as-is
                    result.append(surface)
                }
            }

            result.toString()
        } catch (e: Exception) {
            android.util.Log.e(TAG, "Failed to add furigana", e)
            // Fallback: return original text
            text
        }
    }

    /**
     * Convert hiragana string to katakana
     *
     * Examples:
     * - "ã¡ã‚…ã†ã‚‚ã‚“" â†’ "ãƒãƒ¥ã‚¦ãƒ¢ãƒ³"
     * - "ãã ã•ã„" â†’ "ã‚¯ãƒ€ã‚µã‚¤"
     *
     * Uses Unicode character offset:
     * - Hiragana range: U+3040 ~ U+309F
     * - Katakana range: U+30A0 ~ U+30FF
     * - Offset: 0x60 (96)
     */
    private fun hiraganaToKatakana(hiragana: String): String {
        return hiragana.map { char ->
            if (char in '\u3040'..'\u309F') {
                // Convert hiragana to katakana by adding offset
                (char.code + 0x60).toChar()
            } else {
                // Not hiragana, keep as-is (katakana, punctuation, etc.)
                char
            }
        }.joinToString("")
    }
}
