package com.nihongo.conversation.core.grammar

import com.atilika.kuromoji.ipadic.Token
import com.atilika.kuromoji.ipadic.Tokenizer
import com.nihongo.conversation.domain.model.GrammarComponent
import com.nihongo.conversation.domain.model.GrammarExplanation
import com.nihongo.conversation.domain.model.GrammarType

/**
 * Kuromoji-based Grammar Analyzer
 *
 * Uses Kuromoji (Japanese morphological analyzer) for accurate, fast, offline grammar analysis.
 * Replaces Gemini API calls for grammar analysis to improve speed and save API quota.
 *
 * Features:
 * - 100% offline (no API calls)
 * - Fast analysis (< 100ms per sentence)
 * - Accurate part-of-speech tagging (MeCab IPADIC dictionary)
 * - Thread-safe singleton with lazy initialization
 *
 * @see com.atilika.kuromoji.ipadic.Tokenizer
 */
object KuromojiGrammarAnalyzer {

    private const val TAG = "KuromojiGrammar"

    // Lazy initialization to avoid loading dictionary on app startup
    private val tokenizer: Tokenizer by lazy {
        android.util.Log.d(TAG, "Initializing Kuromoji tokenizer (first use only)...")
        val start = System.currentTimeMillis()
        val t = Tokenizer()
        val elapsed = System.currentTimeMillis() - start
        android.util.Log.d(TAG, "Tokenizer initialized in ${elapsed}ms")
        t
    }

    /**
     * Analyze Japanese sentence using Kuromoji morphological analyzer
     *
     * @param sentence Japanese text to analyze
     * @param userLevel User JLPT level (1=N5/N4, 2=N3/N2, 3=N1) - affects explanation detail
     * @return GrammarExplanation with components, examples, and patterns
     */
    fun analyzeSentence(sentence: String, userLevel: Int = 1): GrammarExplanation {
        val startTime = System.currentTimeMillis()
        android.util.Log.d(TAG, "Analyzing: '$sentence' (level=$userLevel)")

        try {
            // Tokenize with Kuromoji
            val tokens = tokenizer.tokenize(sentence)
            android.util.Log.d(TAG, "Tokenized into ${tokens.size} tokens")

            // Track position manually since Kuromoji doesn't provide character positions
            var currentPosition = 0

            // Convert tokens to grammar components
            val components = tokens.mapIndexed { index, token ->
                val pos = token.partOfSpeechLevel1  // Main POS (å‹•è©, åŠ©è©, etc.)
                val grammarType = mapPosToGrammarType(token)
                val explanation = generateExplanation(token, userLevel)

                android.util.Log.v(TAG, "  [$index] ${token.surface} â†’ $pos â†’ $grammarType")

                val startIndex = currentPosition
                val endIndex = currentPosition + token.surface.length
                currentPosition = endIndex

                GrammarComponent(
                    text = token.surface,
                    type = grammarType,
                    explanation = explanation,
                    startIndex = startIndex,
                    endIndex = endIndex
                )
            }

            // Generate overall and detailed explanations
            val overallExplanation = generateOverallExplanation(sentence, components, userLevel)
            val detailedExplanation = generateDetailedExplanation(components, userLevel)
            val examples = generateExamples(components)
            val relatedPatterns = getRelatedPatterns(components)

            val elapsed = System.currentTimeMillis() - startTime
            android.util.Log.d(TAG, "âœ… Analysis completed in ${elapsed}ms")

            return GrammarExplanation(
                originalText = sentence,
                components = components,
                overallExplanation = overallExplanation,
                detailedExplanation = detailedExplanation,
                examples = examples,
                relatedPatterns = relatedPatterns
            )
        } catch (e: Exception) {
            android.util.Log.e(TAG, "âŒ Analysis failed: ${e.message}", e)

            // Fallback to LocalGrammarAnalyzer on error
            return LocalGrammarAnalyzer.analyzeSentence(sentence, userLevel)
        }
    }

    /**
     * Map Kuromoji POS tags to GrammarType
     *
     * Kuromoji provides detailed POS information:
     * - partOfSpeechLevel1: Main category (å‹•è©, åŠ©è©, etc.)
     * - partOfSpeechLevel2: Sub-category
     * - partOfSpeechLevel3: Detailed classification
     * - conjugationForm: æ´»ç”¨å½¢ (é€£ç”¨å½¢, çµ‚æ­¢å½¢, etc.)
     *
     * Updated 2025-11-02: Accurate mapping to 12 GrammarTypes
     */
    private fun mapPosToGrammarType(token: Token): GrammarType {
        return when (token.partOfSpeechLevel1) {
            "å‹•è©" -> GrammarType.VERB
            "åŠ©è©" -> GrammarType.PARTICLE
            "åŠ©å‹•è©" -> GrammarType.AUXILIARY
            "åè©" -> GrammarType.NOUN
            "å½¢å®¹è©" -> GrammarType.ADJECTIVE
            "å‰¯è©" -> GrammarType.ADVERB
            "é€£ä½“è©" -> GrammarType.RENTAISHI         // â† Fixed: was ADJECTIVE
            "æ¥ç¶šè©" -> GrammarType.CONJUNCTION       // â† Fixed: was EXPRESSION
            "æ„Ÿå‹•è©" -> GrammarType.INTERJECTION      // â† Fixed: was EXPRESSION
            "æ¥é ­è©" -> GrammarType.PREFIX            // â† Fixed: was EXPRESSION
            "è¨˜å·" -> GrammarType.SYMBOL              // â† Fixed: was EXPRESSION
            else -> GrammarType.EXPRESSION
        }
    }

    /**
     * Generate Korean explanation for a token based on POS
     */
    private fun generateExplanation(token: Token, userLevel: Int): String {
        val mainPos = token.partOfSpeechLevel1
        val subPos = token.partOfSpeechLevel2 ?: "*"
        val conjugation = token.conjugationForm ?: "*"

        return when (mainPos) {
            "å‹•è©" -> {
                val detail = when (conjugation) {
                    "é€£ç”¨å½¢" -> "ì—°ìš©í˜• (ã¦í˜•, ãŸí˜• ì•)"
                    "çµ‚æ­¢å½¢" -> "ì¢…ì§€í˜• (ë¬¸ì¥ ë)"
                    "æœªç„¶å½¢" -> "ë¯¸ì—°í˜• (ãªã„, ã† ì•)"
                    "ä»®å®šå½¢" -> "ê°€ì •í˜• (ã° ì•)"
                    "å‘½ä»¤å½¢" -> "ëª…ë ¹í˜•"
                    "åŸºæœ¬å½¢" -> "ê¸°ë³¸í˜•"
                    else -> "ë™ì‚¬"
                }
                if (userLevel == 1) "ë™ì‚¬: $detail" else detail
            }
            "åŠ©è©" -> {
                val particleType = when (subPos) {
                    "æ ¼åŠ©è©" -> "ê²©ì¡°ì‚¬"
                    "æ¥ç¶šåŠ©è©" -> "ì ‘ì†ì¡°ì‚¬"
                    "å‰¯åŠ©è©" -> "ë¶€ì¡°ì‚¬"
                    "çµ‚åŠ©è©" -> "ì¢…ì¡°ì‚¬"
                    else -> "ì¡°ì‚¬"
                }
                getParticleExplanation(token.surface, particleType, userLevel)
            }
            "åŠ©å‹•è©" -> {
                when (token.surface) {
                    "ã§ã™", "ã " -> "ì •ì¤‘ì²´/ë‹¨ì •"
                    "ã¾ã™" -> "ì •ì¤‘ì²´ ë™ì‚¬"
                    "ãŸ", "ã " -> "ê³¼ê±°/ì™„ë£Œ"
                    "ãªã„" -> "ë¶€ì •"
                    "ã‚ˆã†ã ", "ãã†ã " -> "ì¶”ì¸¡/ì–‘íƒœ"
                    "ãŸã„" -> "í¬ë§"
                    "ã‚Œã‚‹", "ã‚‰ã‚Œã‚‹" -> "ìˆ˜ë™/ê°€ëŠ¥/ì¡´ê²½"
                    "ã›ã‚‹", "ã•ã›ã‚‹" -> "ì‚¬ì—­"
                    else -> "ì¡°ë™ì‚¬"
                }
            }
            "åè©" -> {
                when (subPos) {
                    "ä»£åè©" -> "ëŒ€ëª…ì‚¬"
                    "æ•°" -> "ìˆ«ì"
                    "éè‡ªç«‹" -> "ì˜ì¡´ëª…ì‚¬"
                    else -> "ëª…ì‚¬"
                }
            }
            "å½¢å®¹è©" -> {
                if (conjugation != "*") "í˜•ìš©ì‚¬ ($conjugation)"
                else "í˜•ìš©ì‚¬"
            }
            "å‰¯è©" -> "ë¶€ì‚¬"
            "é€£ä½“è©" -> "ì—°ì²´ì‚¬"
            "æ¥ç¶šè©" -> "ì ‘ì†ì‚¬"
            "æ„Ÿå‹•è©" -> "ê°íƒ„ì‚¬"
            "æ¥é ­è©" -> "ì ‘ë‘ì‚¬"
            "è¨˜å·" -> when (subPos) {
                "å¥ç‚¹" -> "ë§ˆì¹¨í‘œ"
                "èª­ç‚¹" -> "ì‰¼í‘œ"
                else -> "ê¸°í˜¸"
            }
            else -> "ê¸°íƒ€"
        }
    }

    /**
     * Get particle-specific explanation (similar to LocalGrammarAnalyzer)
     */
    private fun getParticleExplanation(particle: String, type: String, userLevel: Int): String {
        val info = when (particle) {
            "ã¯" -> "ì£¼ì œ í‘œì‹œ (ì€/ëŠ”)"
            "ãŒ" -> "ì£¼ì–´ í‘œì‹œ (ì´/ê°€)"
            "ã‚’" -> "ëª©ì ì–´ í‘œì‹œ (ì„/ë¥¼)"
            "ã«" -> "ë°©í–¥/ì‹œê°„/ëŒ€ìƒ (ì—/ì—ê²Œ)"
            "ã¸" -> "ë°©í–¥ (ìœ¼ë¡œ)"
            "ã¨" -> "í•¨ê»˜/ì¸ìš© (ì™€/ê³¼)"
            "ã§" -> "ìˆ˜ë‹¨/ì¥ì†Œ (ì—ì„œ/ë¡œ)"
            "ã‹ã‚‰" -> "ì‹œì‘ì  (ë¶€í„°/ì—ì„œ)"
            "ã¾ã§" -> "ì¢…ì  (ê¹Œì§€)"
            "ã®" -> "ì†Œìœ /ê´€ê³„ (~ì˜)"
            "ã‚‚" -> "ì¶”ê°€ (ë„/ì—­ì‹œ)"
            "ã‚„" -> "ì˜ˆì‹œ ë‚˜ì—´ (ì´ë‚˜/ì™€)"
            "ã‹" -> "ì˜ë¬¸ (~ì¸ê°€)"
            "ã­" -> "í™•ì¸ (~ë„¤ìš”)"
            "ã‚ˆ" -> "ê°•ì¡° (~ìš”)"
            else -> type
        }

        return if (userLevel == 1) "$type: $info" else info
    }

    /**
     * Generate overall explanation based on sentence structure
     */
    private fun generateOverallExplanation(
        sentence: String,
        components: List<GrammarComponent>,
        userLevel: Int
    ): String {
        val hasVerb = components.any { it.type == GrammarType.VERB }
        val hasAuxiliary = components.any { it.type == GrammarType.AUXILIARY }
        val particles = components.filter { it.type == GrammarType.PARTICLE }

        return when {
            sentence.endsWith("ã§ã™ã‹") || sentence.endsWith("ã¾ã™ã‹") ->
                "ì •ì¤‘í•œ ì˜ë¬¸ë¬¸ì…ë‹ˆë‹¤. ìƒëŒ€ë°©ì—ê²Œ ì˜ˆì˜ ë°”ë¥´ê²Œ ì§ˆë¬¸í•˜ëŠ” í‘œí˜„ì´ì—ìš”."

            sentence.endsWith("ã‹") ->
                "ì˜ë¬¸ë¬¸ì…ë‹ˆë‹¤. ë¬´ì–¸ê°€ë¥¼ ë¬»ëŠ” ë¬¸ì¥ì´ì—ìš”."

            sentence.contains("ãã ã•ã„") ->
                "ìš”ì²­ì´ë‚˜ ë¶€íƒì„ ë‚˜íƒ€ë‚´ëŠ” ë¬¸ì¥ì…ë‹ˆë‹¤. ê³µì†í•˜ê²Œ ë¶€íƒí•˜ëŠ” í‘œí˜„ì´ì—ìš”."

            sentence.endsWith("ã¾ã—ãŸ") || sentence.endsWith("ã§ã—ãŸ") ->
                "ê³¼ê±°í˜• ì •ì¤‘ì²´ ë¬¸ì¥ì…ë‹ˆë‹¤. ì´ë¯¸ ì¼ì–´ë‚œ ì¼ì„ ì •ì¤‘í•˜ê²Œ í‘œí˜„í•´ìš”."

            sentence.endsWith("ã¾ã™") || sentence.endsWith("ã§ã™") ->
                "í˜„ì¬ ë˜ëŠ” ë¯¸ë˜í˜• ì •ì¤‘ì²´ ë¬¸ì¥ì…ë‹ˆë‹¤. ì˜ˆì˜ ë°”ë¥¸ í‘œí˜„ì´ì—ìš”."

            sentence.contains("ã¾ã›ã‚“") || components.any { it.text == "ãªã„" } ->
                "ë¶€ì •ë¬¸ì…ë‹ˆë‹¤. ì–´ë–¤ ë™ì‘ì„ í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ì˜ë¯¸ì˜ˆìš”."

            components.any { it.text == "ãŸã„" } ->
                "í¬ë§ì´ë‚˜ ìš•êµ¬ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë¬¸ì¥ì…ë‹ˆë‹¤. ~í•˜ê³  ì‹¶ë‹¤ëŠ” í‘œí˜„ì´ì—ìš”."

            hasVerb && hasAuxiliary && particles.isNotEmpty() ->
                "ê¸°ë³¸ì ì¸ ì¼ë³¸ì–´ ë¬¸ì¥ êµ¬ì¡°ë¥¼ ê°–ì¶˜ ë¬¸ì¥ì…ë‹ˆë‹¤. ë™ì‚¬, ì¡°ì‚¬, ì¡°ë™ì‚¬ê°€ ì‚¬ìš©ë˜ì—ˆì–´ìš”."

            else ->
                "ì¼ë³¸ì–´ ë¬¸ì¥ì…ë‹ˆë‹¤. ${components.size}ê°œì˜ í˜•íƒœì†Œë¡œ êµ¬ì„±ë˜ì–´ ìˆì–´ìš”."
        }
    }

    /**
     * Generate detailed explanation with component breakdown
     */
    private fun generateDetailedExplanation(
        components: List<GrammarComponent>,
        userLevel: Int
    ): String {
        val particles = components.filter { it.type == GrammarType.PARTICLE }
        val verbs = components.filter { it.type == GrammarType.VERB }
        val auxiliaries = components.filter { it.type == GrammarType.AUXILIARY }
        val nouns = components.filter { it.type == GrammarType.NOUN }

        val parts = mutableListOf<String>()

        if (nouns.isNotEmpty()) {
            val nounList = nouns.take(3).joinToString(", ") { "'${it.text}'" }
            parts.add("ëª…ì‚¬ [$nounList] ë“±ì´ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
        }

        if (particles.isNotEmpty()) {
            val particleList = particles.map { it.text }.distinct().joinToString(", ")
            parts.add("ì¡°ì‚¬ [${particleList}]ê°€ ë¬¸ì¥ êµ¬ì¡°ë¥¼ ë§Œë“¤ê³  ìˆìŠµë‹ˆë‹¤.")
        }

        if (verbs.isNotEmpty()) {
            parts.add("${verbs.size}ê°œì˜ ë™ì‚¬ê°€ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
        }

        if (auxiliaries.isNotEmpty()) {
            val auxList = auxiliaries.map { it.text }.distinct().joinToString(", ")
            parts.add("ì¡°ë™ì‚¬ [${auxList}]ë¡œ ì •ì¤‘ë„ë‚˜ ì‹œì œë¥¼ í‘œí˜„í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
        }

        when (userLevel) {
            1 -> parts.add("ğŸ’¡ ì´ˆê¸‰ íŒ: ì¡°ì‚¬ì™€ ë™ì‚¬ í™œìš©ì— ì£¼ëª©í•˜ì„¸ìš”.")
            2 -> parts.add("ğŸ’¡ ì¤‘ê¸‰ íŒ: ë¬¸ì¥ì˜ ë‰˜ì•™ìŠ¤ì™€ ì •ì¤‘ë„ë¥¼ íŒŒì•…í•´ë³´ì„¸ìš”.")
            3 -> parts.add("ğŸ’¡ ê³ ê¸‰ íŒ: ë” ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ìœ¼ë¡œ ë°”ê¿”ë³´ëŠ” ì—°ìŠµì„ í•´ë³´ì„¸ìš”.")
        }

        if (parts.isEmpty()) {
            parts.add("í˜•íƒœì†Œ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        }

        return parts.joinToString(" ")
    }

    /**
     * Generate example sentences based on detected patterns
     */
    private fun generateExamples(components: List<GrammarComponent>): List<String> {
        val examples = mutableListOf<String>()

        if (components.any { it.text == "ã¯" }) {
            examples.add("ç§ã¯å­¦ç”Ÿã§ã™ã€‚(ì €ëŠ” í•™ìƒì…ë‹ˆë‹¤)")
        }

        if (components.any { it.text == "ã‚’" }) {
            examples.add("æœ¬ã‚’èª­ã¿ã¾ã™ã€‚(ì±…ì„ ì½ìŠµë‹ˆë‹¤)")
        }

        if (components.any { it.text == "ã¾ã™" }) {
            examples.add("æ¯æ—¥å‹‰å¼·ã—ã¾ã™ã€‚(ë§¤ì¼ ê³µë¶€í•©ë‹ˆë‹¤)")
        }

        if (components.any { it.text == "ãŸã„" }) {
            examples.add("æ—¥æœ¬ã¸è¡ŒããŸã„ã§ã™ã€‚(ì¼ë³¸ì— ê°€ê³  ì‹¶ìŠµë‹ˆë‹¤)")
        }

        if (components.any { it.text == "ãã ã•ã„" }) {
            examples.add("æ•™ãˆã¦ãã ã•ã„ã€‚(ê°€ë¥´ì³ ì£¼ì„¸ìš”)")
        }

        return examples.take(3) // Limit to 3 examples
    }

    /**
     * Get related grammar patterns
     */
    private fun getRelatedPatterns(components: List<GrammarComponent>): List<String> {
        val patterns = mutableSetOf<String>()

        if (components.any { it.text == "ã¯" }) {
            patterns.add("ã€œã¯ã€œã§ã™ (ì£¼ì œ ì œì‹œ)")
        }

        if (components.any { it.text == "ã‚’" }) {
            patterns.add("ã€œã‚’ã€œã™ã‚‹ (íƒ€ë™ì‚¬ ë¬¸í˜•)")
        }

        if (components.any { it.text == "ã¾ã™" }) {
            patterns.add("ã¾ã™í˜• (ì •ì¤‘ì²´)")
        }

        if (components.any { it.type == GrammarType.VERB && it.explanation.contains("é€£ç”¨å½¢") }) {
            patterns.add("ã€œã¦í˜• (ì—°ìš©í˜• í™œìš©)")
        }

        if (components.any { it.text == "ãŸã„" }) {
            patterns.add("ã€œãŸã„ (í¬ë§ í‘œí˜„)")
        }

        if (components.any { it.text == "ãªã„" }) {
            patterns.add("ã€œãªã„ (ë¶€ì •í˜•)")
        }

        return patterns.take(4).toList()
    }

    /**
     * Pre-load tokenizer (optional, call on app startup for faster first analysis)
     */
    fun preload() {
        android.util.Log.d(TAG, "Preloading Kuromoji tokenizer...")
        tokenizer // Access to trigger lazy initialization
    }
}
