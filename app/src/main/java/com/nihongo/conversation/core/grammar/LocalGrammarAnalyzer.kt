package com.nihongo.conversation.core.grammar

import com.nihongo.conversation.domain.model.GrammarComponent
import com.nihongo.conversation.domain.model.GrammarExplanation
import com.nihongo.conversation.domain.model.GrammarType

/**
 * Enhanced Local Grammar Analyzer
 * Provides fast, offline grammar analysis for common patterns
 * Used as primary analyzer for simple sentences and fallback for API failures
 */
object LocalGrammarAnalyzer {

    // Cache for analyzed sentences
    private val cache = mutableMapOf<String, GrammarExplanation>()

    /**
     * Check if sentence can be analyzed locally (avoiding API call)
     */
    fun canAnalyzeLocally(sentence: String): Boolean {
        // Multi-line sentences should use API
        if (sentence.contains("\n")) return false

        // Long sentences are too complex for local analysis
        if (sentence.length > 50) return false

        // Check cache first
        if (cache.containsKey(sentence)) return true

        // Short sentences with common patterns
        if (sentence.length < 30) {
            val commonEndings = listOf(
                "ã§ã™", "ã¾ã™", "ã¾ã—ãŸ", "ã¾ã›ã‚“", "ã§ã—ãŸ",
                "ã§ã™ã‹", "ã¾ã™ã‹", "ã¾ã—ãŸã‹", "ã¾ã›ã‚“ã‹",
                "ãã ã•ã„", "ãŸã„", "ãªã„", "ãªã‹ã£ãŸ"
            )
            if (commonEndings.any { sentence.endsWith(it) }) return true
        }

        // Common greetings and expressions
        val commonPhrases = listOf(
            "ã“ã‚“ã«ã¡ã¯", "ãŠã¯ã‚ˆã†", "ã“ã‚“ã°ã‚“ã¯", "ã•ã‚ˆã†ãªã‚‰",
            "ã‚ã‚ŠãŒã¨ã†", "ã™ã¿ã¾ã›ã‚“", "ã”ã‚ã‚“", "ãŠé¡˜ã„ã—ã¾ã™",
            "ã¯ã˜ã‚ã¾ã—ã¦", "ã‚ˆã‚ã—ã", "ã„ãŸã ãã¾ã™", "ã”ã¡ãã†ã•ã¾"
        )
        if (commonPhrases.any { sentence.contains(it) }) return true

        return false
    }

    /**
     * Enhanced sentence analysis with better pattern recognition
     */
    fun analyzeSentence(sentence: String, userLevel: Int = 1): GrammarExplanation {
        // Return cached result if available
        cache[sentence]?.let { return it }

        val components = mutableListOf<GrammarComponent>()

        // Enhanced particle detection with detailed explanations
        val particlesWithExplanations = mapOf(
            "ã¯" to ParticleInfo("ì£¼ì œ í‘œì‹œ", "ì€/ëŠ”", "ë¬¸ì¥ì˜ ì£¼ì œë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤"),
            "ãŒ" to ParticleInfo("ì£¼ì–´ í‘œì‹œ", "ì´/ê°€", "ë™ì‘ì˜ ì£¼ì²´ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤"),
            "ã‚’" to ParticleInfo("ëª©ì ì–´ í‘œì‹œ", "ì„/ë¥¼", "ë™ì‘ì˜ ëŒ€ìƒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤"),
            "ã«" to ParticleInfo("ë°©í–¥/ì‹œê°„", "ì—/ì—ê²Œ", "ì¥ì†Œ, ì‹œê°„, ëŒ€ìƒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤"),
            "ã¸" to ParticleInfo("ë°©í–¥", "ìœ¼ë¡œ", "ì´ë™ì˜ ë°©í–¥ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤"),
            "ã¨" to ParticleInfo("í•¨ê»˜/ë‚˜ì—´", "ì™€/ê³¼", "ë™ë°˜ìë‚˜ ë‚˜ì—´ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤"),
            "ã§" to ParticleInfo("ìˆ˜ë‹¨/ì¥ì†Œ", "ì—ì„œ/ë¡œ", "í–‰ë™ ì¥ì†Œë‚˜ ìˆ˜ë‹¨ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤"),
            "ã‹ã‚‰" to ParticleInfo("ì‹œì‘ì ", "ë¶€í„°/ì—ì„œ", "ì‹œê°„ì´ë‚˜ ì¥ì†Œì˜ ì‹œì‘ì "),
            "ã¾ã§" to ParticleInfo("ì¢…ì ", "ê¹Œì§€", "ë²”ìœ„ì˜ ëì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤"),
            "ã®" to ParticleInfo("ì†Œìœ /ê´€ê³„", "~ì˜", "ì†Œìœ ë‚˜ ê´€ê³„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤"),
            "ã‚‚" to ParticleInfo("ì¶”ê°€", "ë„/ì—­ì‹œ", "ê°™ì€ ë‚´ìš©ì˜ ì¶”ê°€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤"),
            "ã‚„" to ParticleInfo("ë¶ˆì™„ì „ ë‚˜ì—´", "ì´ë‚˜/ì™€", "ì˜ˆì‹œì  ë‚˜ì—´ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤"),
            "ã‹" to ParticleInfo("ì˜ë¬¸", "~ì¸ê°€", "ì§ˆë¬¸ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤"),
            "ã­" to ParticleInfo("í™•ì¸", "~ë„¤ìš”", "ë™ì˜ë‚˜ í™•ì¸ì„ êµ¬í•©ë‹ˆë‹¤"),
            "ã‚ˆ" to ParticleInfo("ê°•ì¡°", "~ìš”", "ë‹¨ì •ì´ë‚˜ ê°•ì¡°ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤"),
            "ã ã‘" to ParticleInfo("í•œì •", "~ë§Œ", "ë²”ìœ„ë¥¼ í•œì •í•©ë‹ˆë‹¤"),
            "ã°ã‹ã‚Š" to ParticleInfo("ì •ë„", "~ë¿", "ëŒ€ëµì  ì •ë„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤"),
            "ãªã©" to ParticleInfo("ë“±ë“±", "~ë“±", "ì˜ˆì‹œë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤")
        )

        // Detect particles
        particlesWithExplanations.forEach { (particle, info) ->
            var index = sentence.indexOf(particle)
            while (index != -1) {
                val explanation = if (userLevel == 1) {
                    "${info.korean}: ${info.meaning}"
                } else {
                    "${info.function} (${info.korean})"
                }

                components.add(
                    GrammarComponent(
                        text = particle,
                        type = GrammarType.PARTICLE,
                        explanation = explanation,
                        startIndex = index,
                        endIndex = index + particle.length
                    )
                )
                index = sentence.indexOf(particle, index + 1)
            }
        }

        // Enhanced verb patterns with more variations
        val verbPatterns = mapOf(
            // Polite forms
            "ã¾ã™" to VerbInfo("ì •ì¤‘ í˜„ì¬/ë¯¸ë˜", "ë™ì‘ì„ ì •ì¤‘í•˜ê²Œ í‘œí˜„"),
            "ã¾ã—ãŸ" to VerbInfo("ì •ì¤‘ ê³¼ê±°", "ê³¼ê±° ë™ì‘ì„ ì •ì¤‘í•˜ê²Œ í‘œí˜„"),
            "ã¾ã›ã‚“" to VerbInfo("ì •ì¤‘ ë¶€ì •", "ë™ì‘ì„ í•˜ì§€ ì•ŠìŒì„ ì •ì¤‘í•˜ê²Œ í‘œí˜„"),
            "ã¾ã›ã‚“ã§ã—ãŸ" to VerbInfo("ì •ì¤‘ ê³¼ê±° ë¶€ì •", "ê³¼ê±°ì— í•˜ì§€ ì•Šì•˜ìŒì„ í‘œí˜„"),
            "ã¾ã—ã‚‡ã†" to VerbInfo("ì •ì¤‘ ê¶Œìœ ", "í•¨ê»˜ í•˜ìëŠ” ì œì•ˆ"),

            // Te-form patterns
            "ã¦ã„ã‚‹" to VerbInfo("ì§„í–‰í˜•", "í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ë™ì‘"),
            "ã¦ã„ãŸ" to VerbInfo("ê³¼ê±° ì§„í–‰", "ê³¼ê±°ì— ì§„í–‰ ì¤‘ì´ë˜ ë™ì‘"),
            "ã¦ãã ã•ã„" to VerbInfo("ì •ì¤‘í•œ ìš”ì²­", "ê³µì†í•˜ê²Œ ë¶€íƒí•˜ëŠ” í‘œí˜„"),
            "ã¦ã‚‚ã„ã„" to VerbInfo("í—ˆê°€", "í•´ë„ ëœë‹¤ëŠ” í—ˆë½"),
            "ã¦ã¯ã„ã‘ãªã„" to VerbInfo("ê¸ˆì§€", "í•˜ë©´ ì•ˆ ëœë‹¤ëŠ” ê¸ˆì§€"),

            // Want/Need patterns
            "ãŸã„" to VerbInfo("í¬ë§", "í•˜ê³  ì‹¶ë‹¤ëŠ” ìš•êµ¬ í‘œí˜„"),
            "ãŸã‹ã£ãŸ" to VerbInfo("ê³¼ê±° í¬ë§", "í•˜ê³  ì‹¶ì—ˆë˜ ê³¼ê±° ìš•êµ¬"),
            "ãŸããªã„" to VerbInfo("í¬ë§ ë¶€ì •", "í•˜ê³  ì‹¶ì§€ ì•Šë‹¤ëŠ” í‘œí˜„"),

            // Can/Cannot patterns
            "ã§ãã‚‹" to VerbInfo("ê°€ëŠ¥", "í•  ìˆ˜ ìˆë‹¤ëŠ” ëŠ¥ë ¥"),
            "ã§ããªã„" to VerbInfo("ë¶ˆê°€ëŠ¥", "í•  ìˆ˜ ì—†ë‹¤ëŠ” í‘œí˜„"),

            // Plain forms
            "ãªã„" to VerbInfo("ë¶€ì •í˜•", "ë™ì‘ì„ í•˜ì§€ ì•ŠìŒ"),
            "ãªã‹ã£ãŸ" to VerbInfo("ê³¼ê±° ë¶€ì •", "ê³¼ê±°ì— í•˜ì§€ ì•Šì•˜ìŒ"),
            "ã ã‚ã†" to VerbInfo("ì¶”ì¸¡", "ì•„ë§ˆë„ ê·¸ëŸ´ ê²ƒì´ë¼ëŠ” ì¶”ì¸¡"),
            "ã‹ã‚‚ã—ã‚Œãªã„" to VerbInfo("ê°€ëŠ¥ì„±", "ê·¸ëŸ´ì§€ë„ ëª¨ë¥¸ë‹¤ëŠ” í‘œí˜„")
        )

        // Detect verb patterns
        verbPatterns.forEach { (pattern, info) ->
            var index = sentence.indexOf(pattern)
            while (index != -1) {
                val explanation = if (userLevel == 1) {
                    "${info.type}: ${info.meaning}"
                } else {
                    info.type
                }

                components.add(
                    GrammarComponent(
                        text = pattern,
                        type = GrammarType.VERB,
                        explanation = explanation,
                        startIndex = index,
                        endIndex = index + pattern.length
                    )
                )
                index = sentence.indexOf(pattern, index + 1)
            }
        }

        // Common expressions and sentence endings
        val expressions = mapOf(
            // Copula patterns
            "ã§ã™" to ExpressionInfo(GrammarType.AUXILIARY, "ì •ì¤‘ ì¢…ê²°", "ì •ì¤‘í•œ ë¬¸ì¥ ì¢…ê²°"),
            "ã§ã—ãŸ" to ExpressionInfo(GrammarType.AUXILIARY, "ì •ì¤‘ ê³¼ê±°", "ê³¼ê±°ë¥¼ ì •ì¤‘í•˜ê²Œ í‘œí˜„"),
            "ã§ã™ã‹" to ExpressionInfo(GrammarType.EXPRESSION, "ì •ì¤‘ ì˜ë¬¸", "ì •ì¤‘í•œ ì§ˆë¬¸"),
            "ã§ã—ã‚‡ã†" to ExpressionInfo(GrammarType.AUXILIARY, "ì¶”ì¸¡", "ì•„ë§ˆë„ ê·¸ëŸ´ ê²ƒì´ë¼ëŠ” ì¶”ì¸¡"),

            // Request patterns
            "ãã ã•ã„" to ExpressionInfo(GrammarType.EXPRESSION, "ìš”ì²­", "ê³µì†í•œ ë¶€íƒ"),
            "ãŠé¡˜ã„ã—ã¾ã™" to ExpressionInfo(GrammarType.EXPRESSION, "ì •ì¤‘í•œ ë¶€íƒ", "ë§¤ìš° ê³µì†í•œ ë¶€íƒ"),

            // Greeting patterns
            "ã‚ã‚ŠãŒã¨ã†" to ExpressionInfo(GrammarType.EXPRESSION, "ê°ì‚¬", "ê³ ë§ˆì›€ì„ í‘œí˜„"),
            "ã”ã‚ã‚“" to ExpressionInfo(GrammarType.EXPRESSION, "ì‚¬ê³¼", "ë¯¸ì•ˆí•¨ì„ í‘œí˜„"),
            "ã™ã¿ã¾ã›ã‚“" to ExpressionInfo(GrammarType.EXPRESSION, "ì‚¬ê³¼/ì‹¤ë¡€", "ì£„ì†¡í•¨ì´ë‚˜ ì‹¤ë¡€ë¥¼ í‘œí˜„"),

            // Other common patterns
            "ãã†ã§ã™" to ExpressionInfo(GrammarType.EXPRESSION, "ë™ì˜/ì „ë¬¸", "ê·¸ë ‡ë‹¤ëŠ” ë™ì˜ë‚˜ ì „í•´ë“¤ì€ ì •ë³´"),
            "ã¨æ€ã„ã¾ã™" to ExpressionInfo(GrammarType.EXPRESSION, "ìƒê° í‘œí˜„", "ê°œì¸ì  ì˜ê²¬ì´ë‚˜ ìƒê°")
        )

        // Detect expressions
        expressions.forEach { (pattern, info) ->
            var index = sentence.indexOf(pattern)
            while (index != -1) {
                val explanation = if (userLevel == 1) {
                    "${info.type}: ${info.meaning}"
                } else {
                    info.type
                }

                components.add(
                    GrammarComponent(
                        text = pattern,
                        type = info.grammarType,
                        explanation = explanation,
                        startIndex = index,
                        endIndex = index + pattern.length
                    )
                )
                index = sentence.indexOf(pattern, index + 1)
            }
        }

        // Sort and remove overlaps
        val sortedComponents = components
            .sortedBy { it.startIndex }
            .fold(mutableListOf<GrammarComponent>()) { acc, component ->
                if (acc.isEmpty() || acc.last().endIndex <= component.startIndex) {
                    acc.add(component)
                }
                acc
            }

        // Generate explanations
        val overallExplanation = generateOverallExplanation(sentence, sortedComponents, userLevel)
        val detailedExplanation = generateDetailedExplanation(sentence, sortedComponents, userLevel)

        val result = GrammarExplanation(
            originalText = sentence,
            components = sortedComponents,
            overallExplanation = overallExplanation,
            detailedExplanation = detailedExplanation,
            examples = generateExamples(sortedComponents),
            relatedPatterns = getRelatedPatterns(sortedComponents)
        )

        // Cache the result
        if (cache.size < 100) { // Limit cache size
            cache[sentence] = result
        }

        return result
    }

    /**
     * Generate overall explanation based on sentence structure
     */
    private fun generateOverallExplanation(
        sentence: String,
        components: List<GrammarComponent>,
        userLevel: Int
    ): String {
        return when {
            // Questions
            sentence.endsWith("ã§ã™ã‹") || sentence.endsWith("ã¾ã™ã‹") ->
                "ì •ì¤‘í•œ ì˜ë¬¸ë¬¸ì…ë‹ˆë‹¤. ìƒëŒ€ë°©ì—ê²Œ ì˜ˆì˜ ë°”ë¥´ê²Œ ì§ˆë¬¸í•˜ëŠ” í‘œí˜„ì´ì—ìš”."

            sentence.endsWith("ã‹") ->
                "ì˜ë¬¸ë¬¸ì…ë‹ˆë‹¤. ë¬´ì–¸ê°€ë¥¼ ë¬»ëŠ” ë¬¸ì¥ì´ì—ìš”."

            // Requests
            sentence.contains("ãã ã•ã„") ->
                "ìš”ì²­ì´ë‚˜ ë¶€íƒì„ ë‚˜íƒ€ë‚´ëŠ” ë¬¸ì¥ì…ë‹ˆë‹¤. ê³µì†í•˜ê²Œ ë¶€íƒí•˜ëŠ” í‘œí˜„ì´ì—ìš”."

            sentence.contains("ãŠé¡˜ã„ã—ã¾ã™") ->
                "ë§¤ìš° ì •ì¤‘í•œ ë¶€íƒ í‘œí˜„ì…ë‹ˆë‹¤."

            // Past tense
            sentence.endsWith("ã¾ã—ãŸ") || sentence.endsWith("ã§ã—ãŸ") ->
                "ê³¼ê±°í˜• ì •ì¤‘ì²´ ë¬¸ì¥ì…ë‹ˆë‹¤. ì´ë¯¸ ì¼ì–´ë‚œ ì¼ì„ ì •ì¤‘í•˜ê²Œ í‘œí˜„í•´ìš”."

            // Present/Future polite
            sentence.endsWith("ã¾ã™") || sentence.endsWith("ã§ã™") ->
                "í˜„ì¬ ë˜ëŠ” ë¯¸ë˜í˜• ì •ì¤‘ì²´ ë¬¸ì¥ì…ë‹ˆë‹¤. ì˜ˆì˜ ë°”ë¥¸ í‘œí˜„ì´ì—ìš”."

            // Negative
            sentence.contains("ã¾ã›ã‚“") || sentence.contains("ãªã„") ->
                "ë¶€ì •ë¬¸ì…ë‹ˆë‹¤. ì–´ë–¤ ë™ì‘ì„ í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ì˜ë¯¸ì˜ˆìš”."

            // Want/Desire
            sentence.contains("ãŸã„") ->
                "í¬ë§ì´ë‚˜ ìš•êµ¬ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë¬¸ì¥ì…ë‹ˆë‹¤."

            // Progressive
            sentence.contains("ã¦ã„ã‚‹") ->
                "ì§„í–‰í˜• ë¬¸ì¥ì…ë‹ˆë‹¤. í˜„ì¬ ì§„í–‰ ì¤‘ì´ê±°ë‚˜ ìƒíƒœë¥¼ ë‚˜íƒ€ë‚´ìš”."

            // Conditional/Speculative
            sentence.contains("ã§ã—ã‚‡ã†") || sentence.contains("ã ã‚ã†") ->
                "ì¶”ì¸¡ì´ë‚˜ ê°€ëŠ¥ì„±ì„ ë‚˜íƒ€ë‚´ëŠ” ë¬¸ì¥ì…ë‹ˆë‹¤."

            // Default based on components
            components.any { it.type == GrammarType.PARTICLE } ->
                "ê¸°ë³¸ì ì¸ ì¼ë³¸ì–´ ë¬¸ì¥ êµ¬ì¡°ë¥¼ ê°–ì¶˜ ë¬¸ì¥ì…ë‹ˆë‹¤."

            else ->
                "ì¼ë³¸ì–´ í‘œí˜„ì…ë‹ˆë‹¤."
        }
    }

    /**
     * Generate detailed explanation with component analysis
     */
    private fun generateDetailedExplanation(
        sentence: String,
        components: List<GrammarComponent>,
        userLevel: Int
    ): String {
        val particles = components.filter { it.type == GrammarType.PARTICLE }
        val verbs = components.filter { it.type == GrammarType.VERB }
        val expressions = components.filter { it.type == GrammarType.EXPRESSION || it.type == GrammarType.AUXILIARY }

        val parts = mutableListOf<String>()

        // Analyze particles
        if (particles.isNotEmpty()) {
            val particleNames = particles.map { it.text }.distinct().joinToString(", ")
            parts.add("ì¡°ì‚¬ [${particleNames}]ê°€ ì‚¬ìš©ë˜ì–´ ë¬¸ì¥ êµ¬ì¡°ë¥¼ ë§Œë“¤ê³  ìˆìŠµë‹ˆë‹¤.")
        }

        // Analyze verbs
        if (verbs.isNotEmpty()) {
            val verbTypes = verbs.map {
                when {
                    it.text.contains("ã¾ã™") -> "ì •ì¤‘ì²´"
                    it.text.contains("ã¦ã„ã‚‹") -> "ì§„í–‰í˜•"
                    it.text.contains("ãªã„") -> "ë¶€ì •í˜•"
                    it.text.contains("ãŸã„") -> "í¬ë§í˜•"
                    else -> "ë™ì‚¬"
                }
            }.distinct().joinToString(", ")
            parts.add("${verbTypes} í™œìš©ì´ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
        }

        // Analyze expressions
        if (expressions.isNotEmpty()) {
            parts.add("ì¼ë³¸ì–´ íŠ¹ìœ ì˜ í‘œí˜„ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        }

        // Level-specific advice
        when (userLevel) {
            1 -> parts.add("ğŸ’¡ ì´ˆê¸‰ì íŒ: ì¡°ì‚¬ì™€ ë™ì‚¬ í™œìš©ì— ì£¼ëª©í•˜ì„¸ìš”.")
            2 -> parts.add("ğŸ’¡ ì¤‘ê¸‰ì íŒ: ë¬¸ì¥ì˜ ë‰˜ì•™ìŠ¤ì™€ ì •ì¤‘ë„ë¥¼ íŒŒì•…í•´ë³´ì„¸ìš”.")
            3 -> parts.add("ğŸ’¡ ê³ ê¸‰ì íŒ: ë” ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ìœ¼ë¡œ ë°”ê¿”ë³´ëŠ” ì—°ìŠµì„ í•´ë³´ì„¸ìš”.")
        }

        if (parts.isEmpty()) {
            parts.add("ê¸°ë³¸ì ì¸ ì¼ë³¸ì–´ ë¬¸ì¥ì…ë‹ˆë‹¤.")
        }

        return parts.joinToString(" ")
    }

    /**
     * Generate example sentences
     */
    private fun generateExamples(components: List<GrammarComponent>): List<String> {
        val examples = mutableListOf<String>()

        // Generate examples based on detected patterns
        if (components.any { it.text == "ã¯" }) {
            examples.add("ç§ã¯å­¦ç”Ÿã§ã™ã€‚(ì €ëŠ” í•™ìƒì…ë‹ˆë‹¤)")
        }

        if (components.any { it.text == "ã‚’" }) {
            examples.add("æœ¬ã‚’èª­ã¿ã¾ã™ã€‚(ì±…ì„ ì½ìŠµë‹ˆë‹¤)")
        }

        if (components.any { it.text.contains("ã¾ã™") }) {
            examples.add("æ¯æ—¥å‹‰å¼·ã—ã¾ã™ã€‚(ë§¤ì¼ ê³µë¶€í•©ë‹ˆë‹¤)")
        }

        if (components.any { it.text.contains("ãã ã•ã„") }) {
            examples.add("å¾…ã£ã¦ãã ã•ã„ã€‚(ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”)")
        }

        return examples.take(2) // Limit to 2 examples
    }

    /**
     * Get related grammar patterns
     */
    private fun getRelatedPatterns(components: List<GrammarComponent>): List<String> {
        val patterns = mutableSetOf<String>()

        // Add patterns based on components
        if (components.any { it.text == "ã¯" }) {
            patterns.add("ã€œã¯ã€œã§ã™ (ì£¼ì œ ì œì‹œ)")
        }

        if (components.any { it.text == "ã‚’" }) {
            patterns.add("ã€œã‚’ã€œã™ã‚‹ (íƒ€ë™ì‚¬ ë¬¸í˜•)")
        }

        if (components.any { it.text.contains("ã¾ã™") }) {
            patterns.add("ã¾ã™í˜• (ì •ì¤‘ì²´)")
        }

        if (components.any { it.text.contains("ã¦ã„ã‚‹") }) {
            patterns.add("ã€œã¦ã„ã‚‹ (ì§„í–‰/ìƒíƒœ)")
        }

        if (components.any { it.text.contains("ãŸã„") }) {
            patterns.add("ã€œãŸã„ (í¬ë§ í‘œí˜„)")
        }

        return patterns.take(3).toList() // Limit to 3 patterns
    }

    // Data classes for better organization
    private data class ParticleInfo(
        val function: String,
        val korean: String,
        val meaning: String
    )

    private data class VerbInfo(
        val type: String,
        val meaning: String
    )

    private data class ExpressionInfo(
        val grammarType: GrammarType,
        val type: String,
        val meaning: String
    )
}